<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
        h1{text-align: center;}
        h2{text-align: center;}
        h3{text-align: center;}
        h4{text-align: center;}
        code {
  font-family: monospace;
}
        pre{
            background-color: #eee;
            padding: 10px;
            border-radius: 5px;
        }
    </style>
</head>
<body style="background-color:white">
    <h1>Shanmuganathan Chokkalingam</h1>
    <h2>INFO 539 Term project</h2>
    <h3>Technical tutorial on scikit-learn tool</h3>
    <h4><button onclick="window.location.href='https://github.com/Shanmuganathan98/stat-nlp-term-project';"style="background-color: DodgerBlue;">Go to GitHub page</button></h4>
    <div class="main-body">
        <main id="main-doc">
            <section class="main-section" id="Intro">
                <header>
                    <b>What is Scikit-learn?</b>
                </header>
                <p>
                    Scikit-learn, also known as sklearn, is a popular Python library 
                    for machine learning built on top of NumPy, SciPy, and Matplotlib. 
                    It provides a range of efficient tools for data mining and data analysis, 
                    including classification, regression, clustering, and dimensionality reduction 
                    via a consistent interface. Scikit-learn is designed to be simple and easy-to-use, 
                    while also providing a powerful and flexible set of tools for machine learning 
                    practitioners and researchers.                   
                </p>            
                <ul>
                    <li>Simple and efficient tools for data mining and data analysis. 
                        It features various classification, regression and clustering 
                        algorithms including support vector machines, random forests, 
                        gradient boosting, k-means, etc.</li>
                    <li>Accessible to everybody and reusable in various contexts.</li>
                    <li>Built on the top of NumPy, SciPy, and matplotlib.</li>
                    <li>Open source, commercially usable – BSD license.</li>
                </ul>
            </section>
 
            <section class="main-section" id="Requirements">
                <header>
                    <b>Scikit-learn Requirements:</b>
                </header>
                <ul>
                    <li>Python 3.8 or newer</li>
                    <li>NumPy</li>
                    <li>Scipy</li>                
                </ul>
            </section>
 
            <section class="main-section" id="Installation">
                <header>
                    <b>Installation:</b>
                </header>
                <p>
                    Before installing scikit-learn, ensure that you 
                    have NumPy and SciPy installed. Once you have a 
                    working installation of NumPy and SciPy, the easiest 
                    way to install scikit-learn is using pip             
                </p>
                <pre><code> $ pip install -U scikit-learn</code></pre>
            </section>
 
            <section class="main-section" id="Libraries">
                <header>
                    <b>Importing Libraries:</b>
                </header>
                <pre><code>import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.feature_extraction.text import CountVectorizer</code>
                </pre>
            </section>
 
            <section class="main-section" id="Bow">
                <header>
                    <b>Bag-of-words model:</b>
                </header>
 
                <p>
                    The bag-of-words model is a way of representing 
                    text data when modelling text with machine learning 
                    algorithms. This approach is very simple and flexible, 
                    and can be used in a myriad of ways for extracting features 
                    from documents. A bag-of-words is a representation of text 
                    that describes the occurrence of words within a document. 
                    The bag-of-words model is simple to understand and implement 
                    and has seen great success in problems such as language 
                    modelling and document classification. It is called a “bag” of words, 
                    because any information about the order or structure of words in the 
                    document is discarded.                
                </p>
            </section>
 
            <section class="main-section" id="CV">
                <header>
                    <b>CountVectorizer class in scikit-learn:</b>
                </header>
                <p>
                    To construct a bag-of-words model based on the word counts in the respective documents, 
                    the CountVectorizer class implemented in scikit-learn is used.CountVectorizer is used to 
                    fit the bag-or-words model. As a result of fitting the model, the following happens.
                    The fit_transform method of CountVectorizer takes an array of text data, which can be 
                    documents or sentences. The NumPy array consisting of text is used to create the dictionary 
                    consisting of vocabulary indices. The vocabulary indices represent unique words and indices 
                    arranged in the alphabetical order. In the example given below, there are three documents 
                    stored in the NumPy array. The documents stored in the NumPy array represents the outcome of 
                    Indian athletes in current Tokyo Olympics.Numerical feature vector for each document is 
                    created based on frequency of words occurring in each document. For example, the “medal” word 
                    in first document, “Mirabai has won a silver medal in weight lifting in Tokyo Olympics 2021” has 
                    indices of 12 and occurred once in the document. However, the word “in” having indices 8 has 
                    occurred twice in the document. 
                </p>
		<pre>
                <code>
f_names = vectorizer.get_feature_names()
print("Number of Features : {}". format(len(f_names)))
print("Features 1000 to 1050 : \n{}". format(f_names[1000:1050]))
print("Unique words:\n{}".format(vectorizer.get_feature_names()[:10]))</code>
		</pre>
            </section>
            
            <section class="main-section" id="SA">
                <header>
                    <b>Sentimental Analysis using scikit-learn:</b>
                </header>
                <p>
                    I have performed Sentimental analysis on "bag of words meets the bag of popcorns" 
                    dataset using scikit-learn package and identified which classification model is the best. 
                    First load the dataset then split the dataset into Training and Testing sets. Then implement 
                    count vectorizer functions on the dataset. Then create Classification models like LogisticRegression,
                    MultinomialNB, and RandomForestClassifier on the dataset. Finally compare the accuracy of these models.  
                </p>
		<pre>
                <code>
# Code to compute Accuracies of the model
accuracy_logreg = accuracy_score(y_test, pred_logreg).round(2)
accuracy_nb = accuracy_score(y_test, pred_nb).round(2)
accuracy_rf = accuracy_score(y_test, pred_rf).round(2)</code>
                </pre>
            </section>
            
            <section class="main-section" id="Benefits">
                <header>
                    <b>Benefits of using scikit-learn over some other machine learning libraries:</b>
                </header>
                <ul>
                    <li>Consistent interface to machine learning models</li>
                    <li>Provides many tuning parameters but with sensible defaults</li>
                    <li>Rich set of functionalities for companion tasks</li>  
                    <li>Scikit-learn provides a comprehensive set of tools for data pre-processing, 
                        feature selection, model selection, model evaluation, and data visualization. 
                        This makes it easy to carry out end-to-end machine learning workflows using a single library.</li>
                </ul>
            </section>

            <section class="main-section" id="Conclusion">
                <header>
                    <b>Conclusion:</b>
                </header>
                <p>
                   We have done Bag-of-words feature extraction and applied different classification models to the dataset 
                   using scikit-learn library and compared their accuracies. We found that Logistic Regression model gave the 
                   highest accuracy of 88%. We have implemented the scikit-learn module fuctions for model selection, 
                   preprocessing, feature extraction and evaluation. Overall, scikit-learn is an essential tool for anyone working 
                   with machine learning in Python, whether they are just getting started or are seasoned experts in the field.
                </p>
            </section>
            
        </main>
    </div>
</body>
</html>
