{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample set of documents\n",
    "docs = np.array(['Mirabai has won a silver medal in weight lifting in Tokyo olympics 2021',\n",
    "                 'Sindhu has won a bronze medal in badminton in Tokyo olympics',\n",
    "                 'Indian hockey team is in top four team in Tokyo olympics 2021 after 40 years'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the bag-of-words model\n",
    "bag_of_words = vect.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021', '40', 'after', 'badminton', 'bronze', 'four', 'has', 'hockey', 'in', 'indian', 'is', 'lifting', 'medal', 'mirabai', 'olympics', 'silver', 'sindhu', 'team', 'tokyo', 'top', 'weight', 'won', 'years']\n"
     ]
    }
   ],
   "source": [
    "# Get unique words / tokens found in all the documents. The unique words / tokens represents the features\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mirabai': 13, 'has': 6, 'won': 21, 'silver': 15, 'medal': 12, 'in': 8, 'weight': 20, 'lifting': 11, 'tokyo': 18, 'olympics': 14, '2021': 0, 'sindhu': 16, 'bronze': 4, 'badminton': 3, 'indian': 9, 'hockey': 7, 'team': 17, 'is': 10, 'top': 19, 'four': 5, 'after': 2, '40': 1, 'years': 22}\n"
     ]
    }
   ],
   "source": [
    "# Associate the indices with each unique word\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 1 0 2 0 0 1 1 1 1 1 0 0 1 0 1 1 0]\n",
      " [0 0 0 1 1 0 1 0 2 0 0 0 1 0 1 0 1 0 1 0 0 1 0]\n",
      " [1 1 1 0 0 1 0 1 2 1 1 0 0 0 1 0 0 2 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Print the numerical feature vector\n",
    "print(bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>3453_3</td>\n",
       "      <td>0</td>\n",
       "      <td>It seems like more consideration has gone into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>5064_1</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't believe they made this film. Completel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>10905_3</td>\n",
       "      <td>0</td>\n",
       "      <td>Guy is a loser. Can't get girls, needs to buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>10194_3</td>\n",
       "      <td>0</td>\n",
       "      <td>This 30 minute documentary Buñuel made in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>8478_8</td>\n",
       "      <td>1</td>\n",
       "      <td>I saw this movie as a child and it broke my he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  sentiment                                             review\n",
       "0       5814_8          1  With all this stuff going down at the moment w...\n",
       "1       2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2       7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3       3630_4          0  It must be assumed that those who praised this...\n",
       "4       9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
       "...        ...        ...                                                ...\n",
       "24995   3453_3          0  It seems like more consideration has gone into...\n",
       "24996   5064_1          0  I don't believe they made this film. Completel...\n",
       "24997  10905_3          0  Guy is a loser. Can't get girls, needs to buil...\n",
       "24998  10194_3          0  This 30 minute documentary Buñuel made in the ...\n",
       "24999   8478_8          1  I saw this movie as a child and it broke my he...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentimental analysis on \"bag of words meets the bag of popcorns\" dataset\n",
    "data = pd.read_csv(\"C:/Users/user/Downloads/labeledTrainData.tsv\", delimiter=\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and testing sets.\n",
    "def simple_split(data,y,length,split_mark=0.7):\n",
    "    if split_mark > 0 and split_mark < 1:\n",
    "        n = int(split_mark * length)\n",
    "    else:\n",
    "        n - int(split_mark)\n",
    "    x_train = data[:n].copy()\n",
    "    x_test= data[n:].copy()\n",
    "    y_train= y[:n].copy()\n",
    "    y_test= y[n:].copy()\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500,) (7500,) (17500,) (7500,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = simple_split(data.review,data.sentiment,len(data))\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: [8761 8739]\n",
      "Samples per class: [3739 3761]\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples per class: {}\" . format(np.bincount(y_train)))\n",
    "print(\"Samples per class: {}\" . format(np.bincount(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features : 65005\n",
      "Features 1000 to 1050 : \n",
      "['abhisheh', 'abhishek', 'abhor', 'abhorrence', 'abhorrent', 'abhors', 'abi', 'abide', 'abides', 'abiding', 'abigail', 'abigil', 'abilities', 'ability', 'abishai', 'abject', 'abjectly', 'abkani', 'able', 'ably', 'abm', 'abner', 'abnormal', 'abnormality', 'abnormally', 'abo', 'aboard', 'abode', 'abodes', 'abolish', 'abolished', 'abolition', 'abolitionism', 'abolitionists', 'abominable', 'abominably', 'abomination', 'abominations', 'abominator', 'abominibal', 'aboooot', 'aborigin', 'aboriginal', 'aboriginals', 'aborigine', 'aborigines', 'aboriginies', 'aborigins', 'aborigone', 'abort']\n",
      "Unique words:\n",
      "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007']\n"
     ]
    }
   ],
   "source": [
    "f_names = vectorizer.get_feature_names()\n",
    "print(\"Number of Features : {}\". format(len(f_names)))\n",
    "print(\"Features 1000 to 1050 : \\n{}\". format(f_names[1000:1050]))\n",
    "print(\"Unique words:\\n{}\".format(vectorizer.get_feature_names()[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('with', 63728),\n",
       " ('all', 2250),\n",
       " ('this', 57865),\n",
       " ('stuff', 55431),\n",
       " ('going', 24332),\n",
       " ('down', 17279),\n",
       " ('at', 4082),\n",
       " ('the', 57672),\n",
       " ('moment', 37800),\n",
       " ('mj', 37605),\n",
       " ('ve', 61636),\n",
       " ('started', 54657),\n",
       " ('listening', 33896),\n",
       " ('to', 58358),\n",
       " ('his', 27044),\n",
       " ('music', 38654),\n",
       " ('watching', 62795),\n",
       " ('odd', 40456),\n",
       " ('documentary', 16869),\n",
       " ('here', 26685)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "list(islice(vectorizer.vocabulary_.items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>producer</th>\n",
       "      <th>producer9and</th>\n",
       "      <th>producers</th>\n",
       "      <th>produces</th>\n",
       "      <th>producing</th>\n",
       "      <th>product</th>\n",
       "      <th>production</th>\n",
       "      <th>productions</th>\n",
       "      <th>productive</th>\n",
       "      <th>productively</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   producer  producer9and  producers  produces  producing  product  \\\n",
       "0         0             0          0         0          0        0   \n",
       "1         0             0          0         0          0        0   \n",
       "2         0             0          0         0          0        0   \n",
       "3         0             0          0         0          0        1   \n",
       "4         0             0          0         0          0        0   \n",
       "5         0             0          0         0          0        0   \n",
       "6         0             0          0         0          0        0   \n",
       "\n",
       "   production  productions  productive  productively  \n",
       "0           0            0           0             0  \n",
       "1           0            0           0             0  \n",
       "2           0            0           0             0  \n",
       "3           1            0           0             0  \n",
       "4           1            0           0             0  \n",
       "5           0            0           0             0  \n",
       "6           0            0           0             0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 45000\n",
    "j=10\n",
    "words = vectorizer.get_feature_names()[i:i+10]\n",
    "pd.DataFrame(x_train[j:j+7,i:i+10].todense(),columns = words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "scores=cross_val_score(LogisticRegression(max_iter=18000),x_train,y_train,cv=5)\n",
    "print(\"Mean cross validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.999\n",
      "Testing set score:0.879\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=18000)\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred = logreg.predict(x_test) \n",
    "print(\"Training set score:{:.3f}\".format(logreg.score(x_train,y_train)))\n",
    "print(\"Testing set score:{:.3f}\".format(logreg.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3279  460]\n",
      " [ 451 3310]]\n"
     ]
    }
   ],
   "source": [
    "pred_logreg = logreg.predict(x_test)\n",
    "confusion_logreg = confusion_matrix(y_test,pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Logistic Regression model\n",
    "accuracy_logreg = accuracy_score(y_test, pred_logreg).round(2)\n",
    "print(\"Accuracy of Logistic Regression:\",accuracy_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.908\n",
      "Testing set score:0.845\n"
     ]
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"Training set score:{:.3f}\".format(nb.score(x_train,y_train)))\n",
    "print(\"Testing set score:{:.3f}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3275  464]\n",
      " [ 702 3059]]\n"
     ]
    }
   ],
   "source": [
    "pred_nb = nb.predict(x_test)\n",
    "confusion_nb = confusion_matrix(y_test,pred_nb)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Multinomial Naive Bayes model\n",
    "accuracy_nb = accuracy_score(y_test, pred_nb).round(2)\n",
    "print(\"Accuracy of Multinomial Naive Bayes:\",accuracy_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:1.000\n",
      "Testing set score:0.846\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "print(\"Training set score:{:.3f}\".format(rf.score(x_train,y_train)))\n",
    "print(\"Testing set score:{:.3f}\".format(rf.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3139  600]\n",
      " [ 554 3207]]\n"
     ]
    }
   ],
   "source": [
    "pred_rf = rf.predict(x_test)\n",
    "confusion_rf = confusion_matrix(y_test,pred_rf)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Random Forest Classifier model\n",
    "accuracy_rf = accuracy_score(y_test, pred_rf).round(2)\n",
    "print(\"Accuracy of Random Forest Classifier:\",accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
